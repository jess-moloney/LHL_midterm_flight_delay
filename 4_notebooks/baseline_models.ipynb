{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IFPE_Regression(X_train, y_train, X_test, y_test, regressor, deg=None):\n",
    "    \n",
    "    ### INSTANTIATE THE MODEL\n",
    "\n",
    "    ## LINEAR MODELS\n",
    "\n",
    "    # ordinary least squares\n",
    "    if regressor == 'linear':\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        reg = LinearRegression(random_state=0)\n",
    "    \n",
    "    # ridge regression\n",
    "    elif regressor == 'ridge':\n",
    "        from sklearn.linear_model import Ridge\n",
    "        reg = Ridge(random_state=0)\n",
    "\n",
    "    # lasso regression\n",
    "    elif regressor == 'lasso':\n",
    "        from sklearn.linear_model import Lasso\n",
    "        reg = Lasso(random_state=0)\n",
    "\n",
    "    # polynomial linear regression - need to add polynomial features first\n",
    "    # https://www.geeksforgeeks.org/python-implementation-of-polynomial-regression/\n",
    "    # https://scikit-learn.org/stable/modules/linear_model.html#polynomial-regression-extending-linear-models-with-basis-functions\n",
    "    elif regressor == 'polynomial':\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        from sklearn.preprocessing import PolynomialFeatures\n",
    "        poly = PolynomialFeatures(degree = deg)\n",
    "        X_poly = poly.fit_transform(X_train)\n",
    "        X_train = X_poly\n",
    "\n",
    "        # poly.fit(X_poly, y_train)\n",
    "        reg = LinearRegression(random_state=0)\n",
    "\n",
    "    # stochastic gradient descent\n",
    "    elif regressor == 'sgd':\n",
    "        from sklearn.linear_model import SGDRegressor\n",
    "        reg = SGDRegressor(random_state=0)\n",
    "    \n",
    "    ## SUPPORT VECTOR MACHINES\n",
    "\n",
    "    # SVM regression https://scikit-learn.org/stable/modules/svm.html#regression\n",
    "    elif regressor == 'svm':\n",
    "        from sklearn import svm\n",
    "        reg = svm.SVR(random_state=0)\n",
    "\n",
    "    ## DECISION TREES\n",
    "\n",
    "    # decision tree\n",
    "    elif regressor == 'dt':\n",
    "        from sklearn import tree\n",
    "        reg = tree.DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "    ## ENSEMBLE METHODS\n",
    "\n",
    "    # random forest\n",
    "    elif regressor =='rf':\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        reg = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "\n",
    "    # gradient boost\n",
    "    elif regressor =='gb':\n",
    "        from sklearn.ensemble import GradientBoostingRegressor\n",
    "        reg = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "    # voting regressor\n",
    "    elif regressor =='vr':\n",
    "        from sklearn.ensemble import GradientBoostingRegressor\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        from sklearn.ensemble import VotingRegressor\n",
    "        reg1 = GradientBoostingRegressor(random_state=1)\n",
    "        reg2 = RandomForestRegressor(random_state=1)\n",
    "        reg3 = LinearRegression()\n",
    "        reg = VotingRegressor(estimators=[('gb', reg1), ('rf', reg2), ('lr', reg3)])\n",
    "\n",
    "    # xgboost\n",
    "    elif regressor == 'xgb':\n",
    "        import xgboost as xgb\n",
    "        reg = xgb.XGBRegressor(objective ='reg:squarederror', random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "    ### FIT THE MODEL\n",
    "\n",
    "    reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### PREDICT THE RESPONSE FOR THE TEST DATASET\n",
    "\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### EVALUATE THE MODEL\n",
    "\n",
    "    # Mean Absolute Error\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    MAE = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # Root Mean Square Error\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    RMSE = mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "    # r2\n",
    "    from sklearn.metrics import r2_score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Adjusted r2\n",
    "    n = len(X_test)\n",
    "    p = len(X_test[0,:])\n",
    "\n",
    "    Adj_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "\n",
    "    ### COMPARE MODELS\n",
    "    \n",
    "    import pandas as pd\n",
    "    model_comparison = pd.DataFrame({\n",
    "        'Mean Absolute Error': MAE,\n",
    "        'Root Mean Square Error': RMSE,\n",
    "        'R Squared': r2,\n",
    "        'Adjusted R Squared': Adj_r2\n",
    "    }, index  = [str(regressor)])\n",
    "    \n",
    "    return model_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
